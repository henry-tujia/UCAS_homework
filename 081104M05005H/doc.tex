\documentclass[UTF8,a4paper]{ctexart}

% ==========Preamble==========

\usepackage{apacite}
\usepackage{fancyhdr}
\usepackage{geometry}
\usepackage[font=small,labelfont=bf,labelsep=quad,format=hang,textfont=it]{caption}
\usepackage{booktabs}
\usepackage{graphicx}
\usepackage{float}

\pagestyle{plain}
\CTEXsetup[format=\Large\bfseries]{section}
\bibliographystyle{apacite}

% ==========Title==========

\title{\bfseries 计算神经科学综述} 
\author{谈昊\quad2020E8013282037}

% Your name in the first blank and your additional information in \thanks{}
\date{\today}
% delete \today if you don't want the date

% ==========Document==========

\begin{document}
\maketitle

% ==========Abstract==========

\begin{center}
\parbox{130mm}{\zihao{-5}{\bfseries 摘\quad 要：}
% Abstract here
% An example is as follows
计算和数学建模是研究神经系统功能的一种越来越有用的方法。虽然这种建模已经使用了几十年，但最近计算能力和数值技术的进步大大扩展了它的范围，研究活动也相应增加。本文对计算神经科学的方法和应用进行了简要的回顾。
\par
\vspace{1mm}
{\bfseries 关键词：}计算神经科学\quad NLP\quad 实体识别 \quad 知识图谱}
\end{center}

% ==========Body==========

% Example article

\section{前言}
计算神经科学的目标是找到神经系统如何处理信息以产生认知功能和行为的机制解释。该领域的核心是其模型，即对被研究系统的数学和计算描述，它将感觉刺激映射到神经反应和/或神经到行为反应。这些模型从简单到复杂不等。最近，深度神经网络(DNN)已经开始主导人工智能(AI)的几个领域。正如 "神经网络 "一词所暗示的那样，这些模型的灵感来自于生物大脑。然而，当前的DNN忽略了生物神经网络的许多细节。这些简化有助于提高它们的计算效率，使它们能够执行复杂的智能壮举，从感知（如视觉对象和听觉语音识别）到认知任务（如机器翻译），再到运动控制（如玩电脑游戏或控制机械臂）。除了能够对复杂的智能行为进行建模外，DNNs还擅长预测神经对新感觉刺激的反应，其准确度远超目前任何其他可用模型类型。DNNs可以有数百万个参数，这些参数是捕捉成功任务性能所需的领域知识所必需的。与将它们渲染成不可穿透的黑盒子的直觉相反，网络单元的计算特性是四个可直接操纵的元素的结果：输入统计、网络结构、功能目标和学习算法。通过对所有单元的活动和连接性的充分访问、先进的可视化技术以及将网络表征映射到神经数据的分析工具，DNNs代表了构建任务执行模型的强大框架，并将推动计算神经科学的实质性见解。

\section{发展}
计算神经科学的目标是为神经系统如何处理信息以支持认知功能和适应性行为找到机制上的解释。计算模型，即对组成系统的数学和计算描述，旨在捕捉感觉输入到神经反应的映射，并进一步解释表征转换、神经元动态和大脑控制行为的方式。因此，首要的挑战是定义能够解释神经测量以及复杂的适应性行为的模型。从历史上看，计算神经科学家已经用浅层的、线性-非线性的 "调谐 "模型获得了成功，这些模型用于预测低层的感觉加工。然而，大脑是一个深层的循环神经网络，它利用多阶段的非线性变换和复杂的动力学。因此，计算神经科学似乎不可避免地会越来越多地依赖于复杂模型，很可能是来自深层递归神经网络家族的模型。
\par
在视觉领域，实验者(Hubel \& Wiesel, 1959)和理论家(Fukushima, 1980; Lecun \& Bengio, 1995; Riesenhuber \& Poggio, 1999; G. Wallis \& Rolls, 1997)早已意识到需要多阶段的非线性计算。
传统上对浅层模型的关注，既是出于对简单解释的渴望，也是出于拟合复杂模型的困难。手工制作的特征，奠定了现代计算神经科学的基础(Jones \& Palmer，1987)，并不能带我们超越受限的低级调谐函数。作为一种替代方法，研究人员开始直接使用神经数据来拟合模型参数（Dumoulin \& Wandell，2008；M. C.-K. Wu，David，\& Gallant，2006）。这种方法被证明对早期的视觉过程特别成功（Cadena等人，2017；Gao \& Ganguli，2015）。尽管这种方法很优雅，很重要，也很成功，但最终还是受限于从给定系统中收集的神经观测量。即使神经测量技术发展迅速（多站点阵列记录、双光子成像或神经像素，仅举几例），可记录的数据量可能无法提供足够的约束条件来拟合现实中复杂的，即参数丰富的模型。例如，虽然研究人员现在可以从数百个单独的神经元中分别记录，使用的刺激数量可能接近10000个，但深度神经网络（DNN）中的参数数量要大很多个数量级。对于
例如，有影响力的物体识别网络 "AlexNet "有6000万个参数（Krizhevsky，Sutskever，\& Hinton，2012），最新的物体识别网络VGG-16有1.38亿个参数（Simonyan \& Zisserman，2015）。这么高的数量需要编码大量的领域知识，而这些知识是智能行为所需要的。仅仅通过神经测量的瓶颈将这些信息传输到模型中，对于理解和执行真实世界的任务来说，效率可能太低。
\section{研究方法和内容}
\subsection{研究方法}
DNNs通常被训练成优化外部任务目标，而不是来自神经数据。然而，即使是人类水平的性能也并不意味着底层计算采用了相同的机制(Ritter，Barrett，Santoro，\&Botvinick，2017)。 因此，用神经测量来测试模型对于评估网络-内部表征与皮质反应的匹配程度至关重要。幸运的是，计算神经科学拥有丰富的工具箱，可以让研究人员探究甚至是高度复杂的模型，包括DNNs（Diedrichsen \& Kriegeskorte，2017）。
\par
其中一个这样的工具是编码模型，它使用外部固定的特征空间，以便在大量不同的实验条件下（如不同的刺激，图2A-B）对神经反应进行建模。其基本思想是，如果模型和大脑计算出相同的特征，那么模型特征的线性组合应该能够成功预测独立实验数据的神经反应（Naselaris，Kay，Nishimoto，\& Gallant，2011）。对于视觉表征，模型特征空间可以从简单的滤波器，如Gabor-wavelets（Kay，Naselaris，Prenger，\& Gallant，2008），从人类对刺激的标记（Huth，Nishimoto，Vu，\& Gallant，2012年；Mitchell等人，2008年；Naselaris，Prenger，Kay，Oliver，\& Gallant，2009年），或来自DNN不同层的响应（Agrawal，Stansbury，Malik，\& Gallant，2014年；Güçlü \& van Gerven，2015年）。
\par
在多变量响应模式的层面上探究系统，表征相似性分析（RSA，Kriegeskorte \& Kievit，2013；Kriegeskorte，Mur，\& Bandettini，2008；Nili等人，2014）提供了另一种方法来比较DNNs和大脑的内部表征（图2C）。RSA是围绕表征异同矩阵（RDM）的概念，它存储了系统（神经或模型）对所有实验条件对的响应的异同。因此，RDM可以被解释为描述表征几何：引起相似反应的条件在反应空间中相距很近，而导致差异反应的条件将有较大的距离。一个模型表征与大脑表征相似的程度是，它强调刺激之间的相同区别，即模型和大脑被认为是相似的，如果它们引起相似的RDMs。RDMs水平上的比较侧避了定义模型的单位和脑活动测量通道之间的对应映射问题。这种方法可以从fMRI中的体素，（Carlin，Calder，Kriegeskorte，Nili，\& Rowe，2011；Guntupalli，Wheeler，\& Gobbini，2016；Khaligh-Razavi \& Kriegeskorte，2014；Kietzmann，Swisher，König，\& Tong，2012），应用到单细胞记录（Kriegeskorte et al, 2008；Leibo，Liao，Freiwald，Anselmi，\& Poggio，2017；Tsao，Moeller，\& Freiwald，2008），M/EEG数据（Cichy，Pantazis，\& Oliva，2014；Kietzmann，Gert，Tong，\& König，2017），以及包括知觉判断在内的行为测量（Mur等，2013）。
\section{技术领域}
\subsection{关系抽取}
关系实体是人类知识很重要的组成部分，存在于大量的不同文本之间。为了能够从文本中提取出这些实体，人们已经在关系抽取（relation extraction，RE）上研究了数年。这些结构化的实体在人类知识中充当了极其重要的角色，在文本中显显式地或者暗示地隐含着。举个例子，“Steve Jobs是Apple的合伙人”，这句话可以推断出Apple是由Steve Jobs建立的；同样的，可以从“汉密尔顿在美国纽约正式出道”这句话，推断出美国包含纽约。
\par
这些结构化的实体可以被应用在一些下游应用中，例如，知识图谱、搜索引擎和问答系统中。许多科研人员已经投入大量的精力来研究关系提取，期望实现从原始文本中的提取出关系实体。更具体一些，在文本实体识别之后，RE的主要目标就变成了文本内容中识别出所提到的实体之间的关系。
\subsubsection{主要工作}
信息提取(IE)的目的是提取结构性信息。从非结构化文本中获取信息，这就是自然语言处理的一个重要领域(NLP)。关系提取（RE），作为一种重要的在IE中的任务，特别是专注于提取实体之间的关系。一个完整的关系提取系统由命名实体识别器、实体链接器和关系分类器组成。命名实体识别器可以从文本中识别命名实体（如人、组织、位置）。实体链接器将文本中的所有实体与现有知识图谱（KGs，必要的知识图谱）链接起来。关系分类器来按给定的上下文确定实体之间的关系。在这些步骤中，确定关系是最关键和最困难的任务，因为它需要模型来很好地理解语境的语义。因此，RE一般侧重于研究分级部分，也就是所谓的关系分类。一个典型的RE设置是，给定一个句子有两个标记的实体，模型需要将句子分类为预定义关系中的一种。
\subsubsection{主要方法}
早先关于RE的探索是基于统计方法的，例如，模式挖掘、基于特征的方法和图形化模型。最近，随着深度学习的发展，神经网络已经被广泛应用于RE并且取得了很好的效果。这些RE的方法将无结构的文本与结构化的知识联系了起来，并且在几个公共基准上体现出了很好的有效性。
\par
抛开先有RE方法的有效性，大部分算法仍然只在具体的设定上有效。这些方法主要使用大量的人类标注来训练模型，来实现在一个句子中将两个给定的实体识别成事先定义好的关系，这样的目标。然而，真正的世界比这个简单的设定复杂得多：(1) 收集高质量的人类注释代价巨大且耗时，(2)许多长尾关系不能提供大量的训练实例，(3)大多数实体都是用由多个句子组成的长语境进行表达，而且(4)使用预先定义的集合来覆盖这些开放式增长的关系是很困难的。因此，要建立一个有效的、稳健的RE系统，将其应用于真实的世界，仍然有一些更复杂的情况有待进一步调查。
\paragraph{模式提取模型}
首创的方法是使用句子分析工具以识别文本中的语法元素，然后根据这些元素自动构建模式规则\cite{10.1007/3-540-60925-3_51}。为了提取模式时具有更好覆盖率和更高的准确性，后来的工作有着更大的体量、更多的不同格式的模式\cite{10.1145/3097983.3098105},以及更高效的提取方式\cite{zheng-etal-2019-diag}。 由于自动构建的模式可能有错误，上述方法大多需要由人类专家进一步审查，这是基于模式的模型的主要限制。
\paragraph{统计关系提取模型}
与使用模式规则相比，统计方法有着更好的覆盖率并且大大减少了人力。因此，统计关系提取（statistical relation extraction，SRE）已经得到了广泛的研究。
\par
一个典型的SRE方法是基于特征的方法\cite{jiang-zhai-2007-systematic}，其中包括：为目标实体及其相应的上下文，设计词法、句法和语义特征，然后将这些特征输入到关系分类器中。
\par
由于支持向量机(support vector machines，SVM)\cite{wang-2008-examination}的广泛使用，基于核的方法已经被广泛地探讨。通过设计SVM的内核函数，来衡量关系表示和文本实例之间的相似性。
\par
还有一些其他的统计方法可以用来提取和推断隐藏在文本中的暗含信息。图形化方法\cite{yu-lam-2010-jointly}将实体、文本和关系之间的依赖关系抽象成有向无环图的形式，然后利用推理模型，确定正确的关系。
\par
因为其他NLP任务中的嵌入模型的有效性，人们将文本编码成低维的语义空间并从文本嵌入\cite{gormley-etal-2015-improved}中提取关系。 此外，利用KG嵌入进行RE。
\par
虽然SRE已经得到了广泛研究，但它仍然面临着一些挑战。基于特征和核的模型需要很多努力来设计特征或核函数。而图形化和嵌入方法可以预测关系，而不需要太人为干预，但它们仍然受到一些模型能力的限制。
\paragraph{神经关系提取模型}
神经关系提取（Neural relation extraction，NRE）模型引入了神经网络自动提取语义从文本中获取特征。与SRE模型相比，NRE方法可以有效捕捉文本信息并推广到更广泛的数据范围。
\par
NRE的研究主要集中在设计和使用不同的网络架构来获取文本中的关系语义，如递归神经网络（recursive neural networks）\cite{miwa-bansal-2016-end}递归地学习句子的成分表征，卷积的神经网络（convo  lutional neural networks，CNNs）\cite{2017arXiv170708866H}有效建立本地文字模式的模型。循环神经网络（recurrent neural networks，RNNs）\cite{vu-etal-2016-combining}可以更好地进行处理长序列数据，图神经网络（graph neural networks，GNNs）\cite{2019arXiv190906058Z}可以构建词/实体图进行推理。和基于注意力的神经网络利用注意力机制来汇总全局关系信息。
\par 
与SRE模型不同，NRE主要利用的是词嵌入和位置嵌入而不是以手动特征作为输入。词嵌入是NLP中最常用的输入表示法。它将字的语义编码为向量。为了捕捉文本中的实体信息，位置嵌入被用来指定词和实体之间的相对距离。除了词嵌入和位置嵌入，有也有其他工作将句法信息整合入NRE模型。\citeA{xu2015semantic}和\citeA{xu-etal-2015-classifying}在最短依赖路径上采用CNNs和RNNs。\citeA{liu-etal-2015-dependency}提出了一种基于增强的依赖路径的递归神经网络。\citeA{xu2016improved}和\citeA{cai-etal-2016-bidirectional}利用深度RNNs使进一步使用依赖路径。此外，还有将NRE与通用模式结合起来的一些工作。最近，Transformers\citeA{vaswani2017attention}和预训练的语言模型\citeA{devlin2019bert}也被应用在了NER领域并且取得了目前最好的效果。
\subsection{知识图谱}
人类知识是人工智能（AI）的研究方向之一。知识表征和推理，受人类问题的启发解，可以为智能系统表示知识，以使其获得解决复杂任务\cite{newell1959report}的能力。最近，知识图谱作为人类知识结构化的一种形式，引起了学术界和工业界\cite{dong2014knowledge}的极大研究关注。知识图谱是一个结构化的事实的表示，由实体、关系和语义描述组成。实体可以是现实世界的对象和抽象概念，关系表示关系实体之间以及实体的语义描述之间的关系。它们的关系中包含了类型和属性，这些类型和属性具有明确定义的的意义。属性图或归属图被广泛使用。其中，节点和关系具有属性或属性。
\par 
知识图谱是知识的同义词。但有一点不同。当考虑到知识图的图结构时，可以把它看成一个图\cite{bordes2011learning}。当它涉及到形式语义，可以把它作为一个知识库，用于对事实的解释和推理。知识可以用事实三段式来表示，其形式为 (head; relation; tail) 或者 (subject; predicate; object)。例如，在资源描述框架（RDF）下，（爱因斯坦；获得者；诺贝尔奖）。它也可以是以节点为实体，并以边作为关系的有向图表示。
\subsubsection{主要工作}
基于知识图谱的研究的最新进展侧重于知识表征学习（knowledge representation learning,KRL）或知识图嵌入(knowledge graph embedding,KGE)。KGE将实体和关系映射成低维向量\cite{wang2017knowledge}，同时捕捉它们的语义。具体的知识获取任务包括知识图谱完成(knowledge graph completion，KGC)、三重分类、实体识别，以及关系提取。知识感知模型受益于异构信息的整合，知识表示丰富的本体和语义，以及多语言知识。由于其理解和推理常识的能力，许多现实世界的应用，诸如推荐系统和问题回答已经被广泛应用。一些现实世界的产品已有强大的能力来提供更有效的服务，例如，微软的Satori和谷歌的知识图谱\cite{dong2014knowledge}。
\subsubsection{主要方法}
知识表示经历了一个漫长的逻辑和人工智能领域的发展史。图形化的知识表达方式最早可以追溯到1956年由\citeauthor{richens1956preprogramming}提出的语义网的概念。而符号逻辑知识则可以追溯到1959年的通用解难器\cite{newell1959report}。知识库的使用首先是基于知识系统进行推理和解决问题。\cite[MYCIN]{shortliffe2012computer}是最著名的基于规则的医学诊断专家系统与知识库，有着约600条规则。后来，人类知识共同体表达方式见证了框架语言
基于规则和混合表示的发展。大约在在这一时期结束时，开始了Cyc项目，目的是为了汇总出人类知识。资源描述框架（RDF）和网络本体语言(OWL)相继发布，并成为语义网的重要标准。然后，许多开放的知识库或本体出现了，如WordNet、DBpedia、YAGO和Freebase。\citeauthor{stokman1988structuring}在1988年的一张图中提出了现代结构知识的概念。然而，直到2012年，知识图谱获得了极大的普及，因为它的首秀是被使用在谷歌的搜索引擎上，其中的知识融合框架被命名为知识库\cite{dong2014knowledge}，用来构建大规模知识图谱。
\section{预测和展望}
虽然自然语言处理的相关研究比较抽象，但其最基础的研究还是对语法、句法和语义的研究，重点是语言和文本。自然语言处理的难点在于对语言的理解不能仅仅依靠逻辑，还需要有强大的知识基础，需要有强大的知识基础作为支撑，才能更好地处理数据，进一步理解和分析文本。
\par 
对RE打来讲，通过对关系提取模型全面而详细的回顾，概括出四个有希望的方向，可以使RE更强大的：利用更多的数据，进行更高效的学习，处理更复杂的背景和处理更多的领域），并进一步研究两个关键的现有的RE模型所面临的挑战。而对于知识图谱，用于知识表示和推理的数值计算需要一个连续的向量空间来捕捉实体和关系的语义。而基于嵌入的方法对复杂的逻辑推理有一定的局限性，两个关于关系路径和符号逻辑的方向值得进一步探索。一些有前景的方法，如递归关系路径编码，知识图谱上基于GNN的消息传递，以及基于强化学习的路径查找和推理是处理复杂的推理的新兴方法。
\par 
自然语言处理的未来趋势是NLP与众多领域的深度融合，从而为各相关行业创造价值。银行、电器、医疗都是对自然语言处理需求越来越大的领域，NLP+与各行业结合得越紧密，专业化服务的趋势就越强烈。
% ========About apacite===========
% \cite{baddeley1992working}  => (Baddeley, 1992)
% \citeA{baddeley1992working} => Baddeley (1992)

% ==========References==========
\renewcommand{\refname}{参考文献}
% enter your .bib file name in the parentheses in the following line.
\bibliography{ref}

\clearpage


\end{document}
