\documentclass[UTF8,a4paper]{ctexart}

% ==========Preamble==========

\usepackage{apacite}
\usepackage{fancyhdr}
\usepackage{geometry}
\usepackage[font=small,labelfont=bf,labelsep=quad,format=hang,textfont=it]{caption}
\usepackage{booktabs}
\usepackage{graphicx}
\usepackage{float}

\pagestyle{plain}
\CTEXsetup[format=\Large\bfseries]{section}
\bibliographystyle{apacite}

% ==========Title==========

\title{\bfseries 计算神经科学综述} 
\author{谈昊\quad2020E8013282037}

% Your name in the first blank and your additional information in \thanks{}
\date{\today}
% delete \today if you don't want the date

% ==========Document==========

\begin{document}
\maketitle

% ==========Abstract==========

\begin{center}
\parbox{130mm}{\zihao{-5}{\bfseries 摘\quad 要：}
% Abstract here
% An example is as follows
自然语言处理就是将人类交流沟通的语言处理转换成机器能够理解的语言。回顾了自然语言处理的基本概念和处理方法，并着重介绍了实体识别和知识图谱，这两个自然语言处理的下游应用。最后提出了自然语言处理（主要是 命名实体识别和知识图谱）的可能的未来方向。
\par
\vspace{1mm}
{\bfseries 关键词：}自然语言处理\quad NLP\quad 实体识别 \quad 知识图谱}
\end{center}

% ==========Body==========

% Example article

\section{前言}
近年来，通过机器学习技术从自然语言中发现知识的兴趣激增。自然语言处理(NLP)或计算语言学领域的目的是研究建立计算模型的算法和方法，这些模型能够分析自然语言，以执行有用的任务，如实现人与机器之间的交流，改善人与人之间的交流，或仅仅对文本或语音进行处理。
\par
本文对自然语言处理的相关概念、某些发展历史和相关研究问题进行分析，特别是自然语言处理应用领域的知识体系，包括命名实体识别以及图神经网络等领域，并对自然语言处理（主要是命名实体识别和知识图谱）的发展进行了展望和预测。

\section{发展}
自然语言处理是一门包括计算机科学、人工智能和语言学在内的交叉学科，它们既有区别又有交叉。其发展历史可分为四个阶段：1956年以前为胚胎期，1957年至1970年为快速发展期，1971年至1993年为低谷发展期，1994年至今为复兴与融合期。
\par
1936年，图灵（A.M.Turing）发明了图灵机，在纯数学的逻辑符号和现实世界之间建立了联系，为后来计算机的发展奠定了理论基础。20世纪50年代提出的自动机理论是以图灵机计算模型为基础的，被认为是现代计算机科学发展的基础\cite{RN16}。 在快速发展的时期，与上下文无关的语法的引入导致该领域被划分为基于规则的符号派和基于概率的随机派\cite{RN15}，促使了未来的很多年人们都在研究这两种方法到底哪种方法更有效。在低潮期，许多研究者也坚持不懈地进行研究，并取得了一定的成果，语音识别算法在20世纪70年代得到发展，隐马尔科夫模型（Hidden MarkovModel，HMM）被提出并得到广泛应用\cite{RN16}。繁荣期的特点主要有三个方面：首先，概率论方法的大规模应用；其次，计算机的速度和存储量急剧增加，促进了该领域物质基础的提高；最后，网络技术的发展提供了强大的推动力。

\section{研究方法和内容}
\subsection{研究方法}
语言知识可能是模糊的或包含模糊性的。为了解决所发现的语言知识中的歧义性，各种NLP任务，如POS、NER、SBD、词义分解和单词分割等都是利用机器学习模型来进行的。机器学习模型对于解决歧义以及捕捉每一种语言知识具有决定性作用。文献中提出的前卫的NLP算法，依赖于统计机器学习或完全依赖于监督的机器学习模型。在ML技术之前，所有的NLP任务都是使用各种基于规则的方法来进行的，其中大量的规则集都是人工编码的。机器学习的范式与之前大多数语言处理的努力不同。在文献中，针对各种NLP任务的各种ML技术的实现已经被广泛研究。这些机器学习技术可以使用参数化、非参数化或基于内核的学习算法。在基于ML的方法中，ML算法在训练阶段对足够多的预标记数据进行训练以生成模型数据，之后，模型数据在测试阶段用于测试新数据。然而，逐渐地，研究集中在随机机器学习模型上。在这种模型中,对每个输入特征附加一个实值的权重,从而产生软概率决策。
\par
自然语言处理过程大致可以分为五个步骤：第一步是获取预处理语料。第二步是对语句进行预处理，包括语句清洗、分区、词性标签和词的停用等步骤。第三步是表征，也就是向量化，主要是将词句分割成计算机可计算的类型（向量）后进行表示，有助于更好地表达不同词句之间的相似性。第四步模型训练包括传统的监督、半监督和无监督学习模型，可根据应用需求选择。但是，在训练模型的过程中，可能会出现过拟合和欠拟合的情况。过拟合是学习噪声数据的特性，而欠拟合是不能更好地拟合数据。解决过拟合的方法是增加正则化项来增加数据训练量，解决欠拟合的方法是减少正则化项，增加其他特征来处理数据。第五步是评价建模的效果。常用的评价指标包括精度、召回率、F值（F-Measure）等。精确度是衡量检索系统的准确性；召回度是衡量检索系统的完备性；F值是用来反映整体的准确性和召回度的综合指标，F值越高，说明测试方法有效。

\subsection{研究内容}
\subsubsection{词法分析}
词性分析主要包括词性划分、词性标注、命名实体识别和词义辨析。词性和词义标注是词性分析的主要任务。词性是词汇最基本的语法属性，利用词性标注很容易确定每个词的语法范围。词义标注和消歧主要解决多语境下的词义问题，因为一个词在多种语境下可能有多种含义，但在固定语境下的含义往往是确定的。在汉语自然语言处理的歧义模块中，词义分析是最核心的部分\cite{RN18}，只有把歧义工作做好了，其他工作才能顺利进行。命名实体识别的主要任务是识别文本中具有特定含义的词语，如人名、地名等，并为其添加标签，是自然语言处理的重要工具。词性分析主要通过基于规则、基于统计和基于机器学习的方法来实现。
\subsubsection{句法分析}
句法分析的主要任务是确定句子各成分之间的关系，即句法结构，技术实现上主要分为修辞结构分析和依赖性分析，功能上可分为完整句法分析和局部句法分析。完整句法分析是通过一套完整的分析过程得到句子的句法树，局部分析也叫浅层分析，只是得到局部成分的语法。依赖分析是目前使用较多的一种分析方法，就是对句子中词与词之间的依赖关系进行分析。
\subsubsection{语义分析}
语义分析对于不同的语言单位有不同的含义。在词的层面上，语义分析指的是词义辨析；在句子层面上，指的是语义角色标注；在篇章层面上，指的是共指辨析\cite{RN21}。语义分析是目前NLP研究的重点方向。
\section{技术领域}
\subsection{关系抽取}
关系实体是人类知识很重要的组成部分，存在于大量的不同文本之间。为了能够从文本中提取出这些实体，人们已经在关系抽取（relation extraction，RE）上研究了数年。这些结构化的实体在人类知识中充当了极其重要的角色，在文本中显显式地或者暗示地隐含着。举个例子，“Steve Jobs是Apple的合伙人”，这句话可以推断出Apple是由Steve Jobs建立的；同样的，可以从“汉密尔顿在美国纽约正式出道”这句话，推断出美国包含纽约。
\par
这些结构化的实体可以被应用在一些下游应用中，例如，知识图谱\cite{10.5555/2893873.2894046,NIPS2013_5071}、搜索引擎\cite{10.1145/3038912.3052558}和问答系统中。许多科研人员已经投入大量的精力来研究关系提取，期望实现从原始文本中的提取出关系实体。更具体一些，在文本实体识别之后，RE的主要目标就变成了文本内容中识别出所提到的实体之间的关系。
\subsubsection{主要工作}
信息提取(IE)的目的是提取结构性信息。从非结构化文本中获取信息，这就是自然语言处理的一个重要领域(NLP)。关系提取（RE），作为一种重要的在IE中的任务，特别是专注于提取实体之间的关系。一个完整的关系提取系统由命名实体识别器、实体链接器和关系分类器组成。命名实体识别器可以从文本中识别命名实体（如人、组织、位置）。实体链接器将文本中的所有实体与现有知识图谱（KGs，必要的知识图谱）链接起来。关系分类器来按给定的上下文确定实体之间的关系。在这些步骤中，确定关系是最关键和最困难的任务，因为它需要模型来很好地理解语境的语义。因此，RE一般侧重于研究分级部分，也就是所谓的关系分类。一个典型的RE设置是，给定一个句子有两个标记的实体，模型需要将句子分类为预定义关系中的一种。
\subsubsection{主要方法}
早先关于RE的探索是基于统计方法的，例如，模式挖掘\cite{10.1007/3-540-60925-3_51}、基于特征的方法和图形化模型。最近，随着深度学习的发展，神经网络已经被广泛应用于RE并且取得了很好的效果\cite{zhang-etal-2015-bidirectional}。这些RE的方法将无结构的文本与结构化的知识联系了起来，并且在几个公共基准上体现出了很好的有效性。
\par
抛开先有RE方法的有效性，大部分算法仍然只在具体的设定上有效。这些方法主要使用大量的人类标注来训练模型，来实现在一个句子中将两个给定的实体识别成事先定义好的关系，这样的目标。然而，真正的世界比这个简单的设定复杂得多：(1) 收集高质量的人类注释代价巨大且耗时，(2)许多长尾关系不能提供大量的训练实例，(3)大多数实体都是用由多个句子组成的长语境进行表达，而且(4)使用预先定义的集合来覆盖这些开放式增长的关系是很困难的。因此，要建立一个有效的、稳健的RE系统，将其应用于真实的世界，仍然有一些更复杂的情况有待进一步调查。
\paragraph{模式提取模型}
首创的方法是使用句子分析工具以识别文本中的语法元素，然后根据这些元素自动构建模式规则\cite{10.1007/3-540-60925-3_51}。为了提取模式时具有更好覆盖率和更高的准确性，后来的工作有着更大的体量、更多的不同格式的模式\cite{10.1145/3097983.3098105},以及更高效的提取方式\cite{zheng-etal-2019-diag}。 由于自动构建的模式可能有错误，上述方法大多需要由人类专家进一步审查，这是基于模式的模型的主要限制。
\paragraph{统计关系提取模型}
与使用模式规则相比，统计方法有着更好的覆盖率并且大大减少了人力。因此，统计关系提取（statistical relation extraction，SRE）已经得到了广泛的研究。
\par
一个典型的SRE方法是基于特征的方法\cite{jiang-zhai-2007-systematic}，其中包括：为目标实体及其相应的上下文，设计词法、句法和语义特征，然后将这些特征输入到关系分类器中。
\par
由于支持向量机(support vector machines，SVM)\cite{wang-2008-examination}的广泛使用，基于核的方法已经被广泛地探讨。通过设计SVM的内核函数，来衡量关系表示和文本实例之间的相似性。
\par
还有一些其他的统计方法可以用来提取和推断隐藏在文本中的暗含信息。图形化方法\cite{yu-lam-2010-jointly}将实体、文本和关系之间的依赖关系抽象成有向无环图的形式，然后利用推理模型，确定正确的关系。
\par
因为其他NLP任务中的嵌入模型的有效性，人们将文本编码成低维的语义空间并从文本嵌入\cite{gormley-etal-2015-improved}中提取关系。 此外，利用KG嵌入进行RE。
\par
虽然SRE已经得到了广泛研究，但它仍然面临着一些挑战。基于特征和核的模型需要很多努力来设计特征或核函数。而图形化和嵌入方法可以预测关系，而不需要太人为干预，但它们仍然受到一些模型能力的限制。
\paragraph{神经关系提取模型}
神经关系提取（Neural relation extraction，NRE）模型引入了神经网络自动提取语义从文本中获取特征。与SRE模型相比，NRE方法可以有效捕捉文本信息并推广到更广泛的数据范围。
\par
NRE的研究主要集中在设计和使用不同的网络架构来获取文本中的关系语义，如递归神经网络（recursive neural networks）\cite{miwa-bansal-2016-end}递归地学习句子的成分表征，卷积的神经网络（convo  lutional neural networks，CNNs）\cite{2017arXiv170708866H}有效建立本地文字模式的模型。循环神经网络（recurrent neural networks，RNNs）\cite{vu-etal-2016-combining}可以更好地进行处理长序列数据，图神经网络（graph neural networks，GNNs）\cite{2019arXiv190906058Z}可以构建词/实体图进行推理。和基于注意力的神经网络利用注意力机制来汇总全局关系信息。
\par 
与SRE模型不同，NRE主要利用的是词嵌入和位置嵌入而不是以手动特征作为输入。词嵌入是NLP中最常用的输入表示法。它将字的语义编码为向量。为了捕捉文本中的实体信息，位置嵌入被用来指定词和实体之间的相对距离。除了词嵌入和位置嵌入，有也有其他工作将句法信息整合入NRE模型。\citeA{xu2015semantic}和\citeA{xu-etal-2015-classifying}在最短依赖路径上采用CNNs和RNNs。\citeA{liu-etal-2015-dependency}提出了一种基于增强的依赖路径的递归神经网络。\citeA{xu2016improved}和\citeA{cai-etal-2016-bidirectional}利用深度RNNs使进一步使用依赖路径。此外，还有将NRE与通用模式结合起来的一些工作。最近，Transformers\citeA{vaswani2017attention}和预训练的语言模型\citeA{devlin2019bert}也被应用在了NER领域并且取得了目前最好的效果。
\subsection{知识图谱}
人类知识是人工智能（AI）的研究方向之一。知识表征和推理，受人类问题的启发解，可以为智能系统表示知识，以使其获得解决复杂任务\cite{newell1959report}的能力。最近，知识图谱作为人类知识结构化的一种形式，引起了学术界和工业界\cite{dong2014knowledge}的极大研究关注。知识图谱是一个结构化的事实的表示，由实体、关系和语义描述组成。实体可以是现实世界的对象和抽象概念，关系表示关系实体之间以及实体的语义描述之间的关系。它们的关系中包含了类型和属性，这些类型和属性具有明确定义的的意义。属性图或归属图被广泛使用。其中，节点和关系具有属性或属性。
\par 
知识图谱是知识的同义词。但有一点不同。当考虑到知识图的图结构时，可以把它看成一个图\cite{bordes2011learning}。当它涉及到形式语义，可以把它作为一个知识库，用于对事实的解释和推理。知识可以用事实三段式来表示，其形式为 (head; relation; tail) 或者 (subject; predicate; object)。例如，在资源描述框架（RDF）下，（爱因斯坦；获得者；诺贝尔奖）。它也可以是以节点为实体，并以边作为关系的有向图表示。
\subsubsection{主要工作}
基于知识图谱的研究的最新进展侧重于知识表征学习（knowledge representation learning,KRL）或知识图嵌入(knowledge graph embedding,KGE)。KGE将实体和关系映射成低维向量\cite{wang2017knowledge}，同时捕捉它们的语义。具体的知识获取任务包括知识图谱完成(knowledge graph completion，KGC)、三重分类、实体识别，以及关系提取。知识感知模型受益于异构信息的整合，知识表示丰富的本体和语义，以及多语言知识。由于其理解和推理常识的能力，许多现实世界的应用，诸如推荐系统和问题回答已经被广泛应用。一些现实世界的产品已有强大的能力来提供更有效的服务，例如，微软的Satori和谷歌的知识图谱\cite{dong2014knowledge}。
\subsubsection{主要方法}
知识表示经历了一个漫长的逻辑和人工智能领域的发展史。图形化的知识表达方式最早可以追溯到1956年由\citeauthor{richens1956preprogramming}提出的语义网的概念。而符号逻辑知识则可以追溯到1959年的通用解难器\cite{newell1959report}。知识库的使用首先是基于知识系统进行推理和解决问题。\cite[MYCIN]{shortliffe2012computer}是最著名的基于规则的医学诊断专家系统与知识库，有着约600条规则。后来，人类知识共同体表达方式见证了框架语言
基于规则和混合表示的发展。大约在在这一时期结束时，开始了Cyc项目，目的是为了汇总出人类知识。资源描述框架（RDF）和网络本体语言(OWL)相继发布，并成为语义网的重要标准。然后，许多开放的知识库或本体出现了，如WordNet、DBpedia、YAGO和Freebase。\citeauthor{stokman1988structuring}在1988年的一张图中提出了现代结构知识的概念。然而，直到2012年，知识图谱获得了极大的普及，因为它的首秀是被使用在谷歌的搜索引擎上，其中的知识融合框架被命名为知识库\cite{dong2014knowledge}，用来构建大规模知识图谱。
\section{预测和展望}
虽然自然语言处理的相关研究比较抽象，但其最基础的研究还是对语法、句法和语义的研究，重点是语言和文本。自然语言处理的难点在于对语言的理解不能仅仅依靠逻辑，还需要有强大的知识基础，需要有强大的知识基础作为支撑，才能更好地处理数据，进一步理解和分析文本。
\par 
对RE打来讲，通过对关系提取模型全面而详细的回顾，概括出四个有希望的方向，可以使RE更强大的：利用更多的数据，进行更高效的学习，处理更复杂的背景和处理更多的领域），并进一步研究两个关键的现有的RE模型所面临的挑战。而对于知识图谱，用于知识表示和推理的数值计算需要一个连续的向量空间来捕捉实体和关系的语义。而基于嵌入的方法对复杂的逻辑推理有一定的局限性，两个关于关系路径和符号逻辑的方向值得进一步探索。一些有前景的方法，如递归关系路径编码，知识图谱上基于GNN的消息传递，以及基于强化学习的路径查找和推理是处理复杂的推理的新兴方法。
\par 
自然语言处理的未来趋势是NLP与众多领域的深度融合，从而为各相关行业创造价值。银行、电器、医疗都是对自然语言处理需求越来越大的领域，NLP+与各行业结合得越紧密，专业化服务的趋势就越强烈。
% ========About apacite===========
% \cite{baddeley1992working}  => (Baddeley, 1992)
% \citeA{baddeley1992working} => Baddeley (1992)

% ==========References==========
\renewcommand{\refname}{参考文献}
% enter your .bib file name in the parentheses in the following line.
\bibliography{ref}

\clearpage


\end{document}
